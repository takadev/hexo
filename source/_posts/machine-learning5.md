---
title: 機械学習用語4
date: 2017-01-18 00:00:00
tags:
- "機械学習"
- "用語集"
category: 機械学習
---
今回は「[イラストで学ぶ　人工知能概論](http://amzn.to/2jE6IKp)」と同時並行的に読んでいる「[初めてのディープラーニング](http://amzn.to/2k2pyiC)」で出てくる用語について調べてみました。
最近用語ばっかり調べてる気がします。
<!-- More -->

## GPGPU(General Purpose Graphics Processing Unit)
GPGPUはGPUを画像処理ではなく他の目的に応用する技術のこと。

## FLOP(Floating-point Operations Per Second)
1秒間に行える浮動小数点演算の回数を表すコンピュータの処理能力を表す指標の一つ。
よくRebuildでGPUの話をする時にhakさんが使ってますよねw

## CUDA(Compute Unified Device Architecture)

> NVIDIAが提供するGPU向けのC言語の統合開発環境であり、コンパイラ (nvcc) やライブラリなどから構成されている。アプリケーションを実行する基盤となるプラットフォーム／アーキテクチャそのものをCUDAと呼ぶこともある。
> 
> [wiki引用](https://ja.wikipedia.org/wiki/CUDA)

クーダって読むみたいですね。

## 活性化関数が果たす役割
脳でいうシナプスの役割。シナプスは伝わってきた電気信号がある閾値を超えると、発火して次のニューロンに電気信号を伝えるという動きをする。これを模倣したのが活性化関数。
活性化関数は値がある閾値より小さい時は出力値を小さな値に抑え、ある閾値を超えると急に出力値が大きくなるような関数を利用する。

## 活性化関数の種類

### ハイパボリックタンジェント関数

$$f(x) = tanh(x)$$

### シグモイド関数

$$f(x) = \frac{1}{\ 1 + e^{-x}}$$

### ReLU関数
$$f(x) = max(0, x)$$

### ソフトマックス関数
出力層で使用される活性化関数。確率ベクトルを得たい場合に使用される。

## 層の種類

### 全結合層
前の層のノードと自分の層のノードが、全てのエッジで結ばれている層のこと。ノード同士の組み合わせ分のエッジが必要になるのでこの層を処理するための計算量は大きくなる傾向がある。隠れ層の後半や出力層で用いられることが多い。

### 畳み込み層
CNNで用いられる層で、前の層の近隣にあるノード同士の集合が、自分の層のノードとエッジで結ばれている層のこと。近隣にあるノード同士の集合を「局所的なノード」という言い方をする場合がある。画像を畳み込み層を通して計算することは、画像にフィルタをかけることと同じ効果を持つ。画像から特徴抽出を行っている。

### プーリング層
CNNで用いられる層で、前の層の局所的なノードから定る値を自分のノードの値とする層。画像をプーリング層に通して計算すると、画像の少しの変化を吸収する役割を果たす。つまり画像が少し変わっていても同じ結果を返すということ。

## 勾配法
ある関数が与えられている時に、その関数の最小値を取るような変数を求める際に使用される。変数の初期値を定め、その変数に応じた関数の勾配を求める。次に変数を勾配の方向に動かし次の変数の値とし、さらに勾配を求める。これを繰り返し行い最小値となる値に近づけていく。

##　学習率
機械学習の最適化においてどのくらい値を動かすかというハイパーパラメータ。例えば勾配法では繰り返し変数を進める際の、どの程度進めるかという値。

終わり

